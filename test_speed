# Make the gap time reliable or give error if a vehclie does not get a gap time, fix the negative values
# Lane change, switche  the areas and compair the results
# Add vehilcle id in the video
# Sum up the volume of vehcles in each lane to get
# No trucks 

import cv2
import numpy as np
import pandas as pd
import math
import time
from ultralytics import YOLO

### Input ####

VIDEO_PATH = r"C:\Users\MorinE\Desktop\Videos\03-06_01_short.mp4"
OUTPUT_VIDEO = "speed_estimation.avi"
EXCEL_FILENAME = "vehicle_tracking.xlsx"

LINE_REGION_Y_MIN = 1000
LINE_REGION_Y_MAX = 2800
PASSED_LINE_Y = LINE_REGION_Y_MIN

# Video properties
FRAME_WIDTH = 3840
FRAME_HEIGHT = 2160
FPS = 30

# Lane bounderies
LANE1_LEFT = 0
LANE1_RIGHT = 830
LANE2_LEFT = LANE1_RIGHT + 1
LANE2_RIGHT = 1310
LANE3_LEFT = 2690
LANE3_RIGHT = 3170
LANE4_LEFT = LANE3_RIGHT + 1
LANE4_RIGHT = FRAME_WIDTH

# Calibration
PPM = 30  #3840 px ~ 30 m => ~128 px/m

# Detection settings
CONF_THRESHOLD = 0.15 # Lower conf threshold = more detections with false positives
DETECT_CLASSES =  [2, 7]  # car, truck, classes=None - detect all 80 COCO classes (car=2, truck=7, bus=5...)

### Input end ####


# Horizontal band for capturing speed- with a wider range
REGION_PTS = [
    (0, LINE_REGION_Y_MAX),
    (FRAME_WIDTH, LINE_REGION_Y_MAX),
    (FRAME_WIDTH, LINE_REGION_Y_MIN),
    (0, LINE_REGION_Y_MIN)
]


# Minimum time tracked before speed is recorded- increase to detect more accurate speeds
MIN_TRACK_TIME = 0.1  # seconds

# SELECTIVE VIDEO ENHANCEMENT (dakk- avoid headlight flicker)
# We split the frame into left half [0 : MID_X] and right half [MID_X : FRAME_WIDTH].
# apply separate brightness/contrast/gamma
MID_X = FRAME_WIDTH // 2

# Left side (dark side) heavier enhancement
ALPHA_LEFT = 0.9 # contrast
BETA_LEFT  = 20     # brightness
GAMMA_LEFT = 1.2   # gamma correction, 1.2
# Right side (brighter side) lighter enhancement
ALPHA_RIGHT = 1.2
BETA_RIGHT  = 20
GAMMA_RIGHT = 1.1

def adjust_brightness_contrast(frame, alpha=1.2, beta=30):
    """
    Adjust brightness/contrast using OpenCV's convertScaleAbs.
    alpha > 1.0 => more contrast, beta > 0 => more brightness
    """
    return cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)

def adjust_gamma(frame, gamma=1.2):
    """
    Apply gamma correction. gamma > 1.0 => brightens, < 1.0 => darkens
    """
    inv_gamma = 1.0 / gamma
    table = np.array([
        ((i / 255.0) ** inv_gamma) * 255 for i in range(256)
    ]).astype("uint8")
    return cv2.LUT(frame, table)

def enhance_side_by_side(frame):
    """
    Split the frame into left and right halves,
    apply different brightness/contrast/gamma to each,
    then recombine horizontally.
    """
    left_half = frame[:, :MID_X]
    right_half = frame[:, MID_X:]
    # Heavier enhancement on left half
    left_enh = adjust_brightness_contrast(left_half, alpha=ALPHA_LEFT, beta=BETA_LEFT)
    left_enh = adjust_gamma(left_enh, gamma=GAMMA_LEFT)
    # Lighter enhancement on right half
    right_enh = adjust_brightness_contrast(right_half, alpha=ALPHA_RIGHT, beta=BETA_RIGHT)
    right_enh = adjust_gamma(right_enh, gamma=GAMMA_RIGHT)
    return np.hstack([left_enh, right_enh])

def draw_region(img, pts, color=(0, 255, 0), thickness=2):
    """
    Draws a polygon (in this case, a horizontal band) on the frame.
    """
    pts_np = np.array(pts, np.int32).reshape((-1, 1, 2))
    cv2.polylines(img, [pts_np], isClosed=True, color=color, thickness=thickness)

def draw_points(img, points, color=(0, 0, 255), radius=5, thickness=2):
    """
    Draws points
    """
    for point in points:
        cv2.circle(img, point, radius, color, thickness)

LANE_POINTS = [(LANE1_LEFT, PASSED_LINE_Y), (LANE1_RIGHT, PASSED_LINE_Y), (LANE2_LEFT, PASSED_LINE_Y), (LANE2_RIGHT, PASSED_LINE_Y), 
               (LANE3_LEFT, PASSED_LINE_Y), (LANE3_RIGHT, PASSED_LINE_Y), (LANE4_LEFT, PASSED_LINE_Y), (LANE4_RIGHT, PASSED_LINE_Y)]


def determine_lane(x_pos):
    """
    Determine the lane number based on x position
    """
    if LANE1_LEFT <= x_pos <= LANE1_RIGHT:
        return 1
    elif LANE2_LEFT <= x_pos <= LANE2_RIGHT:
        return 2
    elif LANE3_LEFT <= x_pos <= LANE3_RIGHT:
        return 3
    elif LANE4_LEFT <= x_pos <= LANE4_RIGHT:
        return 4
    else:
        return 0  # Default to 0 if not in any lane


def main():
    model = YOLO("yolov8n.pt")
    model.overrides['conf'] = CONF_THRESHOLD
    model.overrides['classes'] = DETECT_CLASSES 
    names = model.model.names
    cap = cv2.VideoCapture(VIDEO_PATH)
    assert cap.isOpened(), f"Error reading video file: {VIDEO_PATH}"

    # annotated output
    video_writer = cv2.VideoWriter(
        OUTPUT_VIDEO,
        cv2.VideoWriter_fourcc(*"mp4v"),
        FPS,
        (FRAME_WIDTH, FRAME_HEIGHT)
    )

    # Track vehicle positions, speeds, and lanes
    start_positions = {}   # track_id -> (start_x, start_y, start_time)
    recorded_speed = {}    # track_id -> speed_kmh
    recorded_lane = {}     # track_id -> lane_number
    
    # Track positions within the region
    region_positions = {}  # track_id -> [(x, y, time), ...] - to track all positions in region
    top_positions = {}     # track_id -> (x, y, time) - position at minimum y in region
    
    # For gap calculations
    lane_vehicles = {1: [], 2: [], 3: [], 4: []}  # lane -> [(track_id, time, y_pos), ...] ordered by y_pos
    unique_lane_vehicles = {1: [], 2: [], 3: [], 4: []}
    speed_records = []
    gap_records = []
    
    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # If the video resolution is not 3840x2160- resize:
        frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))
        frame_count += 1
        current_time = frame_count / FPS  # seconds
        frame = enhance_side_by_side(frame)  # selective enhance
        
        results = model.track(frame, persist=True, show=False)
        if not results or results[0].boxes is None:
            video_writer.write(frame)
            continue

        # Draw region and lane markers
        draw_region(frame, REGION_PTS, color=(0, 255, 0), thickness=2)
        draw_points(frame, LANE_POINTS, color=(0, 255, 0), thickness=2)

        # Extract detection data
        boxes = results[0].boxes.xyxy
        cls_vals = results[0].boxes.cls
        try: 
            ids = results[0].boxes.id
        except Exception: 
            ids = np.arange(len(boxes))

        for i in range(len(boxes)):
            try: 
                track_id = int(ids[i].item())
            except Exception: 
                track_id = i

            x1, y1, x2, y2 = boxes[i]
            center_x = float((x1 + x2) / 2)
            center_y = float((y1 + y2) / 2)

            # Vehicle type
            cls_val = cls_vals[i]
            cls_id = int(cls_val.item()) if hasattr(cls_val, "item") else int(cls_val)
            vehicle_type = names.get(cls_id, "unknown")

            # Store initial position for speed calculation
            if track_id not in start_positions:
                start_positions[track_id] = (center_x, center_y, current_time)
 
            # Check if the vehicle is in the region
            if LINE_REGION_Y_MIN <= center_y <= LINE_REGION_Y_MAX:
                # Initialize tracking for this vehicle in the region if needed
                if track_id not in region_positions:
                    region_positions[track_id] = []
                
                # Store this position in the region
                region_positions[track_id].append((center_x, center_y, current_time))

                # Update top position if this is the lowest y value (closest to top of frame)
                if track_id not in top_positions or center_y < top_positions[track_id][1]:
                    top_positions[track_id] = (center_x, center_y, current_time)

                    # Determine lane based on this position
                    lane_number = determine_lane(center_x)

                    recorded_lane[track_id] = lane_number
                    
                    # If this is a valid lane, add to lane vehicles for gap calculation
                    if lane_number > 0:
                        lane_vehicles[lane_number].append((track_id, current_time, center_y))
                
                # Calculate speed if not already recorded
                if track_id not in recorded_speed:
                    start_x, start_y, start_time = start_positions[track_id]
                    dt = current_time - start_time
                    if dt >= MIN_TRACK_TIME:
                        disp_pixels = abs(center_y - start_y)
                        disp_m = disp_pixels / PPM
                        speed_m_s = disp_m / dt
                        speed_kmh = speed_m_s * 3.6
                        recorded_speed[track_id] = speed_kmh
                        
                        # Record speed data
                        current_lane = recorded_lane.get(track_id, 0)
                        speed_records.append({
                            'Vehicle_ID': track_id,
                            'Time_s': current_time,
                            'Vehicle_Type': vehicle_type,
                            'Center_X': center_x,
                            'Center_Y': center_y,
                            'Speed_km_h': speed_kmh,
                            'Lane': current_lane
                        })

            # Get lane number from stored value if available, else determine from current position
            lane_number = recorded_lane.get(track_id, determine_lane(center_x))

            # Display info
            label = f"{vehicle_type}"
            if track_id in recorded_speed:
                label += f" {recorded_speed[track_id]:.1f} km/h, Lane {lane_number}"
            else: 
                label += f", Lane {lane_number}"

            # Draw bounding box and label
            pt1 = (int(x1), int(y1))
            pt2 = (int(x2), int(y2))
            cv2.rectangle(frame, pt1, pt2, (255, 0, 0), 2)
            cv2.putText(frame, label, (int(x1), int(y1) - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)

        video_writer.write(frame)
        print(f"Frame {frame_count}: Processed {len(boxes)} tracks.")
        

    for track_id, position_data in top_positions.items():
        center_x, center_y, detection_time = position_data
        lane = recorded_lane.get(track_id, 0)

        if 1 <= lane <= 4:
            unique_lane_vehicles[lane].append((track_id, detection_time, center_y))

    for lane in unique_lane_vehicles:
        # Sort by y-position (ascending)
        unique_lane_vehicles[lane].sort(key=lambda x: x[2])

        for i in range(1, len(unique_lane_vehicles[lane])):
            prev_vehicle = unique_lane_vehicles[lane][i-1]
            curr_vehicle = unique_lane_vehicles[lane][i]
        
            prev_id, prev_time, prev_y = prev_vehicle
            curr_id, curr_time, curr_y = curr_vehicle

            if prev_id == curr_id:
                continue

            gap_time = curr_time - prev_time

            if prev_id in recorded_speed:
                prev_speed = recorded_speed[prev_id]  # km/h
                prev_speed_m_s = prev_speed / 3.6
                gap_distance = prev_speed_m_s * gap_time
                
                gap_records.append({
                    'Previous_Vehicle_ID': prev_id,
                    'Current_Vehicle_ID': curr_id,
                    'Lane': lane,
                    'Time_s': curr_time,
                    'Gap_Time_s': gap_time,
                    'Gap_Distance_m': gap_distance
                })
        

    cap.release()
    video_writer.release()
    cv2.destroyAllWindows()
    
    # Save results to Excel
    df_speed = pd.DataFrame(speed_records)
    df_gap = pd.DataFrame(gap_records)
    
    with pd.ExcelWriter(EXCEL_FILENAME, engine='openpyxl') as writer:
        df_speed.to_excel(writer, sheet_name='Speed', index=False)
        df_gap.to_excel(writer, sheet_name='Gap_Analysis', index=False)
    
    print(f"Results saved to '{EXCEL_FILENAME}' in sheets 'Speed' and 'Gap_Analysis'.")

if __name__ == "__main__":
    main()